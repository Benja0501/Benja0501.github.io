{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcmiwBmdq1+c1GbXUL1HAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benja0501/Benja0501.github.io/blob/main/Sistema_cancer_de_mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema Inteligente de Diagnóstico de Cáncer de Mama\n",
        "\n",
        "Celda 1 – Montaje de Google Drive y configuración de entorno"
      ],
      "metadata": {
        "id": "VUwFuDxXA3c2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Sn4bxQA0AX",
        "outputId": "ac5cf7a2-acff-4c2d-e59c-794eff957517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Instalación de dependencias\n",
        "!pip install --quiet \\\n",
        "    tensorflow keras scikit-learn matplotlib seaborn pandas numpy \\\n",
        "    keras-tuner pyngrok fpdf scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Celda 0: instala Streamlit y dependencias ===\n",
        "!pip install streamlit pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltoybLr_A59h",
        "outputId": "353ffe3b-2a09-4372-9036-a899e2461a3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.46.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 2 – Acceso al dataset en Google Drive"
      ],
      "metadata": {
        "id": "4TRlfqNeA7XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# El dataset está en tu Google Drive como ZIP\n",
        "# Ajusta la ruta a tu archivo ZIP en Drive:\n",
        "ZIP_PATH = '/content/drive/MyDrive/DATASET/ultrasound/archive.zip'\n",
        "# Carpeta de destino en Colab:\n",
        "TARGET_DIR = '/content/data'\n",
        "\n",
        "# Descomprímelo si no existe ya:\n",
        "import os\n",
        "if not os.path.exists(TARGET_DIR):\n",
        "    os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "    !unzip -q \"{ZIP_PATH}\" -d \"{TARGET_DIR}\"\n",
        "\n",
        "# Verifica las carpetas 'BENIGN' y 'MALIGNANT'\n",
        "import os\n",
        "print(\"Clases disponibles:\", os.listdir(TARGET_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TdWpKWPA8Zm",
        "outputId": "dd69c926-d7ff-481c-a773-5c0b44723aef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases disponibles: ['Dataset_BUSI_with_GT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 3 – Filtrado de clases “benigno” vs “maligno”"
      ],
      "metadata": {
        "id": "ybCUdRukA93U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# Carpeta con las clases descomprimidas\n",
        "dataset_dir = '/content/data/Dataset_BUSI_with_GT'\n",
        "out_dir = '/content/filtered_data'\n",
        "\n",
        "# Filtrar solo 'benign' y 'malignant', ignorando 'normal'\n",
        "for cls in ['benign', 'malignant']:\n",
        "    src = os.path.join(dataset_dir, cls)\n",
        "    dst = os.path.join(out_dir, cls)\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    for filename in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, filename), dst)\n",
        "\n",
        "# Mostrar recuento por clase\n",
        "for cls in ['benign', 'malignant']:\n",
        "    print(f\"{cls}:\", len(os.listdir(os.path.join(out_dir, cls))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDiTzXggA-wR",
        "outputId": "99e5961e-14ff-4d49-9f32-0ed8ea00ca19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benign: 891\n",
            "malignant: 421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cell 4 – Módulo `preprocessing.py`"
      ],
      "metadata": {
        "id": "mOAeRpjhBAEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile preprocessing.py\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.exposure import equalize_adapthist\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image, target_size=(512,512)):\n",
        "    \"\"\"\n",
        "    Redimensiona la imagen, aplica CLAHE y normaliza a [0,1].\n",
        "    \"\"\"\n",
        "    # Convertir a float32\n",
        "    img_arr = np.array(image, dtype=np.float32)\n",
        "    # Redimensionar con anti_aliasing sobre floats\n",
        "    img = resize(img_arr, target_size, mode='reflect', anti_aliasing=True, preserve_range=True)\n",
        "    # Aplicar CLAHE\n",
        "    img = equalize_adapthist(img)\n",
        "    # Normalizar a [0,1]\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    return img\n",
        "\n",
        "def load_and_preprocess_image(path, target_size=(512,512)):\n",
        "    \"\"\"\n",
        "    Lee una imagen en escala de grises, aplica preprocess_image y devuelve:\n",
        "    - proc: imagen preprocesada (float32 con canal extra)\n",
        "    - orig: imagen redimensionada para visualización\n",
        "    \"\"\"\n",
        "    # Leer en gris y forzar float32\n",
        "    img = imread(path, as_gray=True)\n",
        "    img_arr = np.array(img, dtype=np.float32)\n",
        "    # Preprocesar imagen\n",
        "    proc = preprocess_image(img_arr, target_size)\n",
        "    # Añadir dimensión de canal para compatibilidad con modelos\n",
        "    proc = proc[..., np.newaxis]\n",
        "    # Redimensionar sin anti_aliasing para visualización\n",
        "    orig = resize(img_arr, target_size, mode='reflect', anti_aliasing=False, preserve_range=True)\n",
        "    return proc, orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i67UNKafBBI9",
        "outputId": "8c25c3fc-180f-45aa-f41d-21b09efbba4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocessing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recarga el módulo sin reiniciar el runtime\n",
        "import importlib\n",
        "import preprocessing\n",
        "importlib.reload(preprocessing)\n",
        "from preprocessing import load_and_preprocess_image\n",
        "\n",
        "# Selecciona un ejemplo automático de 'benign'\n",
        "import os\n",
        "first_file = os.listdir('/content/filtered_data/benign')[0]\n",
        "ejemplo = f'/content/filtered_data/benign/{first_file}'\n",
        "proc, orig = load_and_preprocess_image(ejemplo)\n",
        "\n",
        "print('Usando ejemplo:', ejemplo)\n",
        "print('proc:', proc.shape, 'orig:', orig.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_mpc3nwBCSN",
        "outputId": "14590f6b-7d41-4d28-bb30-1119491a4609"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando ejemplo: /content/filtered_data/benign/benign (248)_mask.png\n",
            "proc: (512, 512, 1) orig: (512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 5 – Módulo model_utils.py"
      ],
      "metadata": {
        "id": "jU7CHHyqBDwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_utils.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
        "    Dense, Dropout, BatchNormalization\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import (\n",
        "    ResNet50, InceptionV3, DenseNet121\n",
        ")\n",
        "\n",
        "def load_models(input_shape_gray=(512,512,1), input_shape_rgb=(512,512,3)):\n",
        "    models = {}\n",
        "\n",
        "    # ---- CustomCNN en gris ----\n",
        "    inp = Input(shape=input_shape_gray)\n",
        "    x = Conv2D(32, (3,3), activation='relu')(inp)\n",
        "    x = MaxPooling2D((2,2))(x); x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x); x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, (3,3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x); x = BatchNormalization()(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    custom = Model(inputs=inp, outputs=out)\n",
        "    custom.compile(\n",
        "        optimizer=Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
        "    )\n",
        "    models['CustomCNN'] = custom\n",
        "\n",
        "    # ---- Helper para pretrained RGB ----\n",
        "    def _build_pretrained(base_cls, name):\n",
        "        inp_rgb = Input(shape=input_shape_rgb)\n",
        "        base = base_cls(weights='imagenet', include_top=False, input_tensor=inp_rgb)\n",
        "        base.trainable = False\n",
        "        y = GlobalAveragePooling2D()(base.output)\n",
        "        y = Dense(256, activation='relu')(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation='sigmoid')(y)\n",
        "        m = Model(inputs=inp_rgb, outputs=y)\n",
        "        m.compile(\n",
        "            optimizer=Adam(1e-4),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
        "        )\n",
        "        models[name] = m\n",
        "\n",
        "    # ---- Construcción de los 3 pretrained ----\n",
        "    _build_pretrained(ResNet50,    'ResNet50')\n",
        "    _build_pretrained(InceptionV3, 'InceptionV3')\n",
        "    _build_pretrained(DenseNet121, 'DenseNet121')\n",
        "    return models\n",
        "\n",
        "# Funciones de inferencia\n",
        "def predict_image(model, img_preprocessed):\n",
        "    \"\"\"\n",
        "    Para CustomCNN (input: 512x512x1, valores [0,1])\n",
        "    \"\"\"\n",
        "    # Asegura (512,512,1) → (1,512,512,1)\n",
        "    if img_preprocessed.ndim == 2:  # Si es (512,512)\n",
        "        x = img_preprocessed[..., np.newaxis]\n",
        "    elif img_preprocessed.shape[-1] != 1:\n",
        "        x = img_preprocessed[..., np.newaxis]\n",
        "    else:\n",
        "        x = img_preprocessed\n",
        "    x = x[np.newaxis, ...]\n",
        "    y_prob = float(model.predict(x)[0, 0])\n",
        "    pred = int(y_prob > 0.5)\n",
        "    # Saliency map dummy (puedes reemplazar por uno real)\n",
        "    saliency = np.zeros(img_preprocessed.shape[:2])\n",
        "    return pred, y_prob, saliency\n",
        "\n",
        "def predict_image_rgb(model, img_preprocessed):\n",
        "    \"\"\"\n",
        "    Para modelos RGB (input: 512x512x3, valores [0,1])\n",
        "    \"\"\"\n",
        "    if img_preprocessed.shape[-1] == 1:\n",
        "        # Si tiene 1 canal, repite para hacer 3 canales\n",
        "        x = np.repeat(img_preprocessed, 3, axis=-1)\n",
        "    else:\n",
        "        x = img_preprocessed\n",
        "    x = x[np.newaxis, ...]\n",
        "    y_prob = float(model.predict(x)[0, 0])\n",
        "    pred = int(y_prob > 0.5)\n",
        "    saliency = np.zeros(img_preprocessed.shape[:2])\n",
        "    return pred, y_prob, saliency\n",
        "\n",
        "def generate_saliency_map(model, img_input):\n",
        "    img_tensor = tf.convert_to_tensor(np.expand_dims(img_input, 0), dtype=tf.float32)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        pred = model(img_tensor)\n",
        "    grads = tape.gradient(pred, img_tensor)\n",
        "    saliency = tf.reduce_max(tf.abs(grads), axis=-1)[0]\n",
        "    saliency = (saliency - tf.reduce_min(saliency)) / (\n",
        "        tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-8\n",
        "    )\n",
        "    return saliency.numpy()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ms = load_models()\n",
        "    for name, m in ms.items():\n",
        "        m.save(f'/content/models/{name}.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--8Qk-1PBEbf",
        "outputId": "fa71dbd9-d09e-41ea-ba51-189967d8cd44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recarga el módulo sin reiniciar el runtime\n",
        "import importlib\n",
        "import model_utils\n",
        "importlib.reload(model_utils)\n",
        "from model_utils import load_models, generate_saliency_map\n",
        "\n",
        "# Carga los modelos\n",
        "models_dict = load_models()\n",
        "print(\"Modelos disponibles:\", list(models_dict.keys()))\n",
        "\n",
        "# Prueba Grad-CAM con el CustomCNN sobre el ejemplo preprocesado\n",
        "model = models_dict['CustomCNN']\n",
        "sal = generate_saliency_map(model, proc)\n",
        "print('Saliency map shape:', sal.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZAtXVdnBGQS",
        "outputId": "bc2f5c6c-1562-4a1b-e7c9-ee2899ce3678"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos disponibles: ['CustomCNN', 'ResNet50', 'InceptionV3', 'DenseNet121']\n",
            "Saliency map shape: (512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 6 – Generadores con ImageDataGenerator"
      ],
      "metadata": {
        "id": "Tq80N-dCBHYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 6 corregida ---\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# Tamaño de entrada de los modelos\n",
        "IMG_SIZE = (512, 512)\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Habilitar growth en GPU si es posible\n",
        "try:\n",
        "    for gpu in tf.config.list_physical_devices('GPU'):\n",
        "        tf.config.set_memory_growth(gpu, True)\n",
        "except Exception as e:\n",
        "    print('No se pudo configurar memory growth:', e)\n",
        "\n",
        "# Generadores RGB para los pre-entrenados\n",
        "datagen_rgb = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_gen = datagen_rgb.flow_from_directory(\n",
        "    '/content/filtered_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "val_gen = datagen_rgb.flow_from_directory(\n",
        "    '/content/filtered_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Generadores grayscale para CustomCNN\n",
        "datagen_gray = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_gen_gray = datagen_gray.flow_from_directory(\n",
        "    '/content/filtered_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "val_gen_gray = datagen_gray.flow_from_directory(\n",
        "    '/content/filtered_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print('Train RGB samples:', train_gen.samples)\n",
        "print('Validation RGB samples:', val_gen.samples)\n",
        "print('Train gray samples:', train_gen_gray.samples)\n",
        "print('Validation gray samples:', val_gen_gray.samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQVmy1a7BIat",
        "outputId": "d423d559-c6e1-4f14-a7d3-b8779461effc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1050 images belonging to 2 classes.\n",
            "Found 262 images belonging to 2 classes.\n",
            "Found 1050 images belonging to 2 classes.\n",
            "Found 262 images belonging to 2 classes.\n",
            "Train RGB samples: 1050\n",
            "Validation RGB samples: 262\n",
            "Train gray samples: 1050\n",
            "Validation gray samples: 262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 7 – Entrenamiento de los modelos con callbacks"
      ],
      "metadata": {
        "id": "dCytv59dBJ_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "from model_utils import load_models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "EPOCHS = 10\n",
        "# Cargar y seleccionar 4 modelos para no quedarnos sin RAM\n",
        "all_models = load_models()\n",
        "models_to_train = ['ResNet50','InceptionV3','DenseNet121','CustomCNN']\n",
        "models_dict = {n: all_models[n] for n in models_to_train}\n",
        "\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "history = {}\n",
        "\n",
        "for name, mdl in models_dict.items():\n",
        "    print(f\"▶️ Entrenando {name}\")\n",
        "    ckpt = f\"/content/models/{name}.h5\"\n",
        "    cp_cb = ModelCheckpoint(ckpt, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    es_cb = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "    # Selección de generador\n",
        "    tgen, vgen = (train_gen_gray, val_gen_gray) if name=='CustomCNN' else (train_gen, val_gen)\n",
        "    history[name] = mdl.fit(tgen, validation_data=vgen,\n",
        "                             epochs=EPOCHS, callbacks=[cp_cb, es_cb])\n",
        "\n",
        "    # Limpiar memoria\n",
        "    del mdl\n",
        "    K.clear_session()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_LFR6joBK88",
        "outputId": "48f56173-24d1-45b4-cd1e-85b87eb8b4da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Entrenando ResNet50\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5643 - auc: 0.5145 - loss: 0.9395 - precision: 0.2802 - recall: 0.2743\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79771, saving model to /content/models/ResNet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 120ms/step - accuracy: 0.5646 - auc: 0.5147 - loss: 0.9385 - precision: 0.2806 - recall: 0.2743 - val_accuracy: 0.7977 - val_auc: 0.6878 - val_loss: 0.5665 - val_precision: 0.9429 - val_recall: 0.3929\n",
            "Epoch 2/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6788 - auc: 0.5984 - loss: 0.6428 - precision: 0.5256 - recall: 0.3229\n",
            "Epoch 2: val_accuracy did not improve from 0.79771\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - accuracy: 0.6789 - auc: 0.5985 - loss: 0.6427 - precision: 0.5258 - recall: 0.3228 - val_accuracy: 0.7328 - val_auc: 0.7652 - val_loss: 0.5533 - val_precision: 1.0000 - val_recall: 0.1667\n",
            "Epoch 3/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7540 - auc: 0.7173 - loss: 0.5395 - precision: 0.7049 - recall: 0.3446\n",
            "Epoch 3: val_accuracy did not improve from 0.79771\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - accuracy: 0.7540 - auc: 0.7172 - loss: 0.5395 - precision: 0.7049 - recall: 0.3446 - val_accuracy: 0.7366 - val_auc: 0.8004 - val_loss: 0.5511 - val_precision: 1.0000 - val_recall: 0.1786\n",
            "Epoch 4/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7651 - auc: 0.7398 - loss: 0.5226 - precision: 0.8230 - recall: 0.2932\n",
            "Epoch 4: val_accuracy did not improve from 0.79771\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.7651 - auc: 0.7398 - loss: 0.5226 - precision: 0.8228 - recall: 0.2934 - val_accuracy: 0.7710 - val_auc: 0.8115 - val_loss: 0.5066 - val_precision: 1.0000 - val_recall: 0.2857\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "▶️ Entrenando InceptionV3\n",
            "Epoch 1/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7053 - auc: 0.6641 - loss: 0.5860 - precision: 0.5937 - recall: 0.2053\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81679, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 184ms/step - accuracy: 0.7055 - auc: 0.6646 - loss: 0.5858 - precision: 0.5944 - recall: 0.2059 - val_accuracy: 0.8168 - val_auc: 0.8582 - val_loss: 0.4501 - val_precision: 0.8750 - val_recall: 0.5000\n",
            "Epoch 2/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8197 - auc: 0.9083 - loss: 0.3840 - precision: 0.8298 - recall: 0.5391\n",
            "Epoch 2: val_accuracy improved from 0.81679 to 0.82061, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.8197 - auc: 0.9084 - loss: 0.3840 - precision: 0.8299 - recall: 0.5393 - val_accuracy: 0.8206 - val_auc: 0.8746 - val_loss: 0.4081 - val_precision: 0.9111 - val_recall: 0.4881\n",
            "Epoch 3/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8668 - auc: 0.9397 - loss: 0.3204 - precision: 0.8341 - recall: 0.7518\n",
            "Epoch 3: val_accuracy improved from 0.82061 to 0.83969, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.8668 - auc: 0.9397 - loss: 0.3204 - precision: 0.8342 - recall: 0.7517 - val_accuracy: 0.8397 - val_auc: 0.8925 - val_loss: 0.3824 - val_precision: 0.9773 - val_recall: 0.5119\n",
            "Epoch 4/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8781 - auc: 0.9444 - loss: 0.3017 - precision: 0.8788 - recall: 0.7669\n",
            "Epoch 4: val_accuracy improved from 0.83969 to 0.84733, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.8782 - auc: 0.9444 - loss: 0.3016 - precision: 0.8788 - recall: 0.7669 - val_accuracy: 0.8473 - val_auc: 0.9022 - val_loss: 0.3653 - val_precision: 0.9783 - val_recall: 0.5357\n",
            "Epoch 5/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9053 - auc: 0.9571 - loss: 0.2541 - precision: 0.9157 - recall: 0.7872\n",
            "Epoch 5: val_accuracy did not improve from 0.84733\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - accuracy: 0.9053 - auc: 0.9571 - loss: 0.2541 - precision: 0.9156 - recall: 0.7873 - val_accuracy: 0.8473 - val_auc: 0.9034 - val_loss: 0.3616 - val_precision: 0.9783 - val_recall: 0.5357\n",
            "Epoch 6/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9100 - auc: 0.9676 - loss: 0.2258 - precision: 0.8797 - recall: 0.8239\n",
            "Epoch 6: val_accuracy did not improve from 0.84733\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.9100 - auc: 0.9676 - loss: 0.2258 - precision: 0.8798 - recall: 0.8239 - val_accuracy: 0.8473 - val_auc: 0.9081 - val_loss: 0.3494 - val_precision: 0.9400 - val_recall: 0.5595\n",
            "Epoch 7/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9194 - auc: 0.9782 - loss: 0.1952 - precision: 0.9205 - recall: 0.8278\n",
            "Epoch 7: val_accuracy improved from 0.84733 to 0.85115, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - accuracy: 0.9194 - auc: 0.9781 - loss: 0.1953 - precision: 0.9204 - recall: 0.8278 - val_accuracy: 0.8511 - val_auc: 0.9085 - val_loss: 0.3663 - val_precision: 0.9592 - val_recall: 0.5595\n",
            "Epoch 8/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9282 - auc: 0.9789 - loss: 0.1958 - precision: 0.9242 - recall: 0.8527\n",
            "Epoch 8: val_accuracy did not improve from 0.85115\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.9281 - auc: 0.9789 - loss: 0.1958 - precision: 0.9242 - recall: 0.8527 - val_accuracy: 0.8473 - val_auc: 0.9136 - val_loss: 0.3652 - val_precision: 0.9400 - val_recall: 0.5595\n",
            "Epoch 9/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9125 - auc: 0.9690 - loss: 0.2056 - precision: 0.9035 - recall: 0.8131\n",
            "Epoch 9: val_accuracy did not improve from 0.85115\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - accuracy: 0.9125 - auc: 0.9690 - loss: 0.2056 - precision: 0.9035 - recall: 0.8132 - val_accuracy: 0.8015 - val_auc: 0.9071 - val_loss: 0.3505 - val_precision: 0.6778 - val_recall: 0.7262\n",
            "Epoch 10/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9190 - auc: 0.9740 - loss: 0.1964 - precision: 0.9138 - recall: 0.8227\n",
            "Epoch 10: val_accuracy improved from 0.85115 to 0.85496, saving model to /content/models/InceptionV3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.9191 - auc: 0.9740 - loss: 0.1964 - precision: 0.9139 - recall: 0.8228 - val_accuracy: 0.8550 - val_auc: 0.9140 - val_loss: 0.3544 - val_precision: 0.9423 - val_recall: 0.5833\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "▶️ Entrenando DenseNet121\n",
            "Epoch 1/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7209 - auc: 0.6685 - loss: 0.5725 - precision: 0.6427 - recall: 0.2340\n",
            "Epoch 1: val_accuracy improved from -inf to 0.82443, saving model to /content/models/DenseNet121.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 204ms/step - accuracy: 0.7212 - auc: 0.6693 - loss: 0.5720 - precision: 0.6438 - recall: 0.2349 - val_accuracy: 0.8244 - val_auc: 0.8469 - val_loss: 0.4568 - val_precision: 1.0000 - val_recall: 0.4524\n",
            "Epoch 2/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8522 - auc: 0.9149 - loss: 0.3728 - precision: 0.8738 - recall: 0.6284\n",
            "Epoch 2: val_accuracy did not improve from 0.82443\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.8523 - auc: 0.9150 - loss: 0.3726 - precision: 0.8739 - recall: 0.6284 - val_accuracy: 0.8244 - val_auc: 0.8587 - val_loss: 0.4115 - val_precision: 0.8654 - val_recall: 0.5357\n",
            "Epoch 3/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8588 - auc: 0.9297 - loss: 0.3369 - precision: 0.8508 - recall: 0.7044\n",
            "Epoch 3: val_accuracy improved from 0.82443 to 0.83588, saving model to /content/models/DenseNet121.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - accuracy: 0.8588 - auc: 0.9297 - loss: 0.3368 - precision: 0.8509 - recall: 0.7044 - val_accuracy: 0.8359 - val_auc: 0.8685 - val_loss: 0.4018 - val_precision: 0.9362 - val_recall: 0.5238\n",
            "Epoch 4/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9054 - auc: 0.9556 - loss: 0.2660 - precision: 0.8980 - recall: 0.8013\n",
            "Epoch 4: val_accuracy improved from 0.83588 to 0.83969, saving model to /content/models/DenseNet121.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.9053 - auc: 0.9555 - loss: 0.2661 - precision: 0.8979 - recall: 0.8012 - val_accuracy: 0.8397 - val_auc: 0.8755 - val_loss: 0.3959 - val_precision: 0.9565 - val_recall: 0.5238\n",
            "Epoch 5/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9072 - auc: 0.9558 - loss: 0.2613 - precision: 0.8996 - recall: 0.8117\n",
            "Epoch 5: val_accuracy did not improve from 0.83969\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - accuracy: 0.9072 - auc: 0.9558 - loss: 0.2613 - precision: 0.8996 - recall: 0.8117 - val_accuracy: 0.8397 - val_auc: 0.8806 - val_loss: 0.3819 - val_precision: 0.8750 - val_recall: 0.5833\n",
            "Epoch 6/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9115 - auc: 0.9653 - loss: 0.2286 - precision: 0.9022 - recall: 0.8142\n",
            "Epoch 6: val_accuracy did not improve from 0.83969\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - accuracy: 0.9115 - auc: 0.9653 - loss: 0.2286 - precision: 0.9021 - recall: 0.8142 - val_accuracy: 0.8321 - val_auc: 0.8895 - val_loss: 0.3899 - val_precision: 0.8846 - val_recall: 0.5476\n",
            "Epoch 7/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9205 - auc: 0.9707 - loss: 0.2194 - precision: 0.9028 - recall: 0.8436\n",
            "Epoch 7: val_accuracy improved from 0.83969 to 0.84351, saving model to /content/models/DenseNet121.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - accuracy: 0.9205 - auc: 0.9707 - loss: 0.2194 - precision: 0.9028 - recall: 0.8435 - val_accuracy: 0.8435 - val_auc: 0.8847 - val_loss: 0.3838 - val_precision: 0.8644 - val_recall: 0.6071\n",
            "Epoch 8/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9231 - auc: 0.9536 - loss: 0.2213 - precision: 0.8919 - recall: 0.8244\n",
            "Epoch 8: val_accuracy did not improve from 0.84351\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - accuracy: 0.9231 - auc: 0.9537 - loss: 0.2212 - precision: 0.8920 - recall: 0.8246 - val_accuracy: 0.8435 - val_auc: 0.8884 - val_loss: 0.3761 - val_precision: 0.8525 - val_recall: 0.6190\n",
            "Epoch 9/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9234 - auc: 0.9773 - loss: 0.1983 - precision: 0.8908 - recall: 0.8890\n",
            "Epoch 9: val_accuracy did not improve from 0.84351\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.9234 - auc: 0.9772 - loss: 0.1984 - precision: 0.8908 - recall: 0.8888 - val_accuracy: 0.8397 - val_auc: 0.8903 - val_loss: 0.4097 - val_precision: 0.9375 - val_recall: 0.5357\n",
            "Epoch 10/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9311 - auc: 0.9681 - loss: 0.2015 - precision: 0.9140 - recall: 0.8459\n",
            "Epoch 10: val_accuracy did not improve from 0.84351\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 68ms/step - accuracy: 0.9311 - auc: 0.9681 - loss: 0.2015 - precision: 0.9140 - recall: 0.8459 - val_accuracy: 0.8435 - val_auc: 0.8917 - val_loss: 0.4080 - val_precision: 0.9216 - val_recall: 0.5595\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "▶️ Entrenando CustomCNN\n",
            "Epoch 1/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6595 - auc: 0.6205 - loss: 0.6270 - precision: 0.4666 - recall: 0.3172\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67939, saving model to /content/models/CustomCNN.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 71ms/step - accuracy: 0.6597 - auc: 0.6207 - loss: 0.6269 - precision: 0.4671 - recall: 0.3169 - val_accuracy: 0.6794 - val_auc: 0.5908 - val_loss: 0.6273 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6832 - auc: 0.6592 - loss: 0.6036 - precision: 0.5566 - recall: 0.2645\n",
            "Epoch 2: val_accuracy did not improve from 0.67939\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6832 - auc: 0.6592 - loss: 0.6036 - precision: 0.5565 - recall: 0.2645 - val_accuracy: 0.6794 - val_auc: 0.6437 - val_loss: 0.5984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6919 - auc: 0.7174 - loss: 0.5811 - precision: 0.6425 - recall: 0.2702\n",
            "Epoch 3: val_accuracy improved from 0.67939 to 0.72901, saving model to /content/models/CustomCNN.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6919 - auc: 0.7173 - loss: 0.5811 - precision: 0.6423 - recall: 0.2701 - val_accuracy: 0.7290 - val_auc: 0.6838 - val_loss: 0.5753 - val_precision: 0.7407 - val_recall: 0.2381\n",
            "Epoch 4/10\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6718 - auc: 0.6666 - loss: 0.6014 - precision: 0.5280 - recall: 0.3083\n",
            "Epoch 4: val_accuracy did not improve from 0.72901\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6719 - auc: 0.6667 - loss: 0.6013 - precision: 0.5282 - recall: 0.3083 - val_accuracy: 0.7099 - val_auc: 0.6914 - val_loss: 0.5895 - val_precision: 0.7857 - val_recall: 0.1310\n",
            "Epoch 5/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7114 - auc: 0.7138 - loss: 0.5612 - precision: 0.5908 - recall: 0.2961\n",
            "Epoch 5: val_accuracy did not improve from 0.72901\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.7114 - auc: 0.7139 - loss: 0.5612 - precision: 0.5909 - recall: 0.2962 - val_accuracy: 0.6336 - val_auc: 0.6523 - val_loss: 0.6016 - val_precision: 0.4189 - val_recall: 0.3690\n",
            "Epoch 6/10\n",
            "\u001b[1m262/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6974 - auc: 0.6780 - loss: 0.5768 - precision: 0.5263 - recall: 0.3241\n",
            "Epoch 6: val_accuracy did not improve from 0.72901\n",
            "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6976 - auc: 0.6782 - loss: 0.5767 - precision: 0.5269 - recall: 0.3241 - val_accuracy: 0.6870 - val_auc: 0.6935 - val_loss: 0.5771 - val_precision: 0.5238 - val_recall: 0.2619\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile metrics_utils.py\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from scipy.stats import chi2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def matthews_corrcoef(cm):\n",
        "    tp, fp, fn, tn = cm[1,1], cm[0,1], cm[1,0], cm[0,0]\n",
        "    num = tp*tn - fp*fn\n",
        "    den = np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
        "    return num/den if den!=0 else 0\n",
        "\n",
        "def mcnemar_test(y_true, y1, y2):\n",
        "    b = np.sum((y1==y_true)&(y2!=y_true))\n",
        "    c = np.sum((y1!=y_true)&(y2==y_true))\n",
        "    if (b+c)>25:\n",
        "        stat = (abs(b-c)-1)**2/(b+c)\n",
        "    else:\n",
        "        stat = (abs(b-c))**2/(b+c) if (b+c)>0 else 0\n",
        "    p = 1 - chi2.cdf(stat, df=1)\n",
        "    return stat, p\n",
        "\n",
        "def evaluate_on_dataset(test_dir, img_size=512, batch_size=8):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "      - df: DataFrame con columnas y_true, <Modelo>_proba, <Modelo>_pred\n",
        "      - comparisons: dict con claves \"i_j\" de McNemar\n",
        "      - cms: lista de rutas a los PNG de cada matriz de confusión\n",
        "    \"\"\"\n",
        "    # 1) Listar rutas y etiquetas\n",
        "    paths, labels = [], []\n",
        "    for cls,label in [('benign',0),('malignant',1)]:\n",
        "        d = os.path.join(test_dir, cls)\n",
        "        for fn in os.listdir(d):\n",
        "            paths.append(os.path.join(d, fn))\n",
        "            labels.append(label)\n",
        "    y = np.array(labels)\n",
        "    results = {'y_true': y}\n",
        "    cms = []\n",
        "\n",
        "    # 2) Cargar modelos entrenados\n",
        "    models = {\n",
        "        \"ResNet50\":   load_model(os.path.join('models','ResNet50.h5')),\n",
        "        \"InceptionV3\":load_model(os.path.join('models','InceptionV3.h5')),\n",
        "        \"DenseNet121\":load_model(os.path.join('models','DenseNet121.h5')),\n",
        "        \"CustomCNN\":  load_model(os.path.join('models','CustomCNN.h5')),\n",
        "    }\n",
        "    names = list(models.keys())\n",
        "\n",
        "    # 3) Para cada modelo: abrir imagen, resize, normalizar, predecir\n",
        "    for name, mdl in models.items():\n",
        "        print(f\"▶️ Evaluando {name}\")\n",
        "        X = []\n",
        "        for p in paths:\n",
        "            img = Image.open(p)\n",
        "            img = img.convert('RGB') if name!=\"CustomCNN\" else img.convert('L')\n",
        "            img = img.resize((img_size, img_size))\n",
        "            arr = np.asarray(img, np.float32) / 255.0\n",
        "            if name==\"CustomCNN\":\n",
        "                arr = arr[...,None]\n",
        "            X.append(arr)\n",
        "        X = np.stack(X, axis=0)\n",
        "\n",
        "        probas = mdl.predict(X, batch_size=batch_size).ravel()\n",
        "        preds  = (probas>0.5).astype(int)\n",
        "        results[f\"{name}_proba\"] = probas\n",
        "        results[f\"{name}_pred\"]  = preds\n",
        "\n",
        "        # generar y guardar heatmap de su matriz de confusión\n",
        "        cm = confusion_matrix(y, preds)\n",
        "        fig, ax = plt.subplots(figsize=(4,4))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                    xticklabels=['benign','malignant'], yticklabels=['benign','malignant'])\n",
        "        ax.set_title(f\"CM – {name}\")\n",
        "        fn = f\"cm_{name}.png\"\n",
        "        fig.savefig(fn, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "        cms.append(fn)\n",
        "\n",
        "    # 4) McNemar en cada par\n",
        "    comps = {}\n",
        "    for i in range(len(names)):\n",
        "        for j in range(i+1, len(names)):\n",
        "            comps[f\"{i}_{j}\"] = mcnemar_test(\n",
        "                y,\n",
        "                results[f\"{names[i]}_pred\"],\n",
        "                results[f\"{names[j]}_pred\"]\n",
        "            )\n",
        "\n",
        "    # 5) construir DataFrame y lista de métricas para el reporte\n",
        "    df = pd.DataFrame(results)\n",
        "    metrics_list = []\n",
        "    for name in names:\n",
        "        cm = confusion_matrix(y, df[f\"{name}_pred\"])\n",
        "        rpt = classification_report(y, df[f\"{name}_pred\"],\n",
        "                                    target_names=['benign','malignant'],\n",
        "                                    output_dict=True)\n",
        "        metrics_list.append({\n",
        "            'model': name,\n",
        "            'accuracy': rpt['accuracy'],\n",
        "            'sensitivity': rpt['malignant']['recall'],\n",
        "            'specificity': rpt['benign']['recall'],\n",
        "            'f1': rpt['malignant']['f1-score'],\n",
        "            'mcc': matthews_corrcoef(cm)\n",
        "        })\n",
        "\n",
        "    return df, comps, cms, metrics_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6NhnIc1BMiS",
        "outputId": "f776b272-f5b5-45a7-d2ff-d2c73f8e829a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting metrics_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile report_utils.py\n",
        "from fpdf import FPDF\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Para un solo modelo con mapa de saliencia (opcional, aún útil para otros flujos)\n",
        "def generate_pdf_report(image_original, heatmap, diagnosis, confidence, model_name):\n",
        "    combined_path = \"combined_temp.png\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    axes[0].imshow(image_original, cmap='gray')\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis('off')\n",
        "    axes[1].imshow(image_original, cmap='gray')\n",
        "    axes[1].imshow(heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[1].set_title(\"Mapa de Saliencia\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(combined_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=\"Reporte de Diagnóstico Mamario\", ln=1, align='C')\n",
        "    pdf.ln(5)\n",
        "\n",
        "    pdf.cell(200, 10, txt=f\"Modelo utilizado: {model_name}\", ln=1)\n",
        "    pdf.cell(200, 10, txt=f\"Fecha: {time.strftime('%Y-%m-%d %H:%M:%S')}\", ln=1)\n",
        "    pdf.cell(200, 10, txt=f\"Diagnóstico: {'Positivo para Cáncer' if diagnosis else 'Negativo para Cáncer'}\", ln=1)\n",
        "    pdf.cell(200, 10, txt=f\"Confianza: {confidence*100:.2f}%\", ln=1)\n",
        "    pdf.ln(10)\n",
        "\n",
        "    pdf.cell(200, 10, txt=\"Imágenes de Diagnóstico:\", ln=1)\n",
        "    pdf.image(combined_path, w=180)\n",
        "\n",
        "    pdf_path = \"diagnostico_mama.pdf\"\n",
        "    pdf.output(pdf_path)\n",
        "\n",
        "    os.remove(combined_path)\n",
        "    return pdf_path\n",
        "\n",
        "# NUEVO: Para PDF consolidado de inferencia múltiple de modelos\n",
        "def generate_multi_model_report(image_original, results, output_path=\"diagnostico_mama_multimodelo.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", 'B', 18)\n",
        "    pdf.cell(0, 12, \"Diagnóstico de Cáncer de Mama\", ln=1, align='C')\n",
        "    pdf.set_font(\"Arial\", '', 13)\n",
        "    pdf.cell(0, 10, \"Reporte comparativo de modelos de IA\", ln=1, align='C')\n",
        "    pdf.ln(6)\n",
        "\n",
        "    # Imagen original\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.cell(0, 8, \"Imagen de entrada:\", ln=1)\n",
        "    img_path = \"_temp_input.png\"\n",
        "    if isinstance(image_original, np.ndarray):\n",
        "        plt.imsave(img_path, image_original, cmap='gray')\n",
        "    else:\n",
        "        image_original.save(img_path)\n",
        "    pdf.image(img_path, x=40, w=120)\n",
        "    os.remove(img_path)\n",
        "    pdf.ln(3)\n",
        "\n",
        "    # Resultados por modelo\n",
        "    for res in results:\n",
        "        pdf.set_font(\"Arial\", 'B', 12)\n",
        "        pdf.cell(0, 8, f\"Modelo: {res['model']}\", ln=1)\n",
        "        pdf.set_font(\"Arial\", '', 11)\n",
        "        pdf.cell(0, 8, f\"Diagnóstico: {'Positivo' if res['prediction'] else 'Negativo'}\", ln=1)\n",
        "        pdf.cell(0, 8, f\"Probabilidad: {res['probability']:.2%}\", ln=1)\n",
        "        pdf.ln(1)\n",
        "        # Saliency map\n",
        "        saliency_path = f\"_temp_sal_{res['model']}.png\"\n",
        "        plt.imsave(saliency_path, res['saliency'], cmap='jet')\n",
        "        pdf.image(saliency_path, x=60, w=90)\n",
        "        os.remove(saliency_path)\n",
        "        pdf.ln(5)\n",
        "\n",
        "    pdf.output(output_path)\n",
        "    return output_path\n",
        "\n",
        "# PDF comparativo con métricas, matrices, McNemar\n",
        "def generate_comparison_report(metrics_list, model_names, comparisons, confusion_images, output_path='comparativo_mama.pdf'):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.cell(200, 10, txt=\"Reporte Comparativo de Modelos\", ln=1, align='C')\n",
        "    pdf.cell(200, 10, txt=f\"Fecha: {time.strftime('%Y-%m-%d %H:%M:%S')}\", ln=1)\n",
        "    pdf.ln(5)\n",
        "\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.cell(0, 10, \"Métricas Generales\", ln=1)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "\n",
        "    col_width = 32\n",
        "    headers = [\"Modelo\", \"Precisión\", \"Sensibilidad\", \"Especificidad\", \"F1-Score\", \"MCC\"]\n",
        "    for header in headers:\n",
        "        pdf.cell(col_width, 8, header, border=1, align='C')\n",
        "    pdf.ln()\n",
        "\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    for m in metrics_list:\n",
        "        pdf.cell(col_width, 8, m['model'], border=1)\n",
        "        pdf.cell(col_width, 8, f\"{m['accuracy']:.3f}\", border=1, align='C')\n",
        "        pdf.cell(col_width, 8, f\"{m['sensitivity']:.3f}\", border=1, align='C')\n",
        "        pdf.cell(col_width, 8, f\"{m['specificity']:.3f}\", border=1, align='C')\n",
        "        pdf.cell(col_width, 8, f\"{m['f1']:.3f}\", border=1, align='C')\n",
        "        pdf.cell(col_width, 8, f\"{m['mcc']:.3f}\", border=1, align='C')\n",
        "        pdf.ln()\n",
        "    pdf.ln(5)\n",
        "\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.cell(0, 10, \"Comparaciones Estadísticas (McNemar)\", ln=1)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    for key, (stat, p) in comparisons.items():\n",
        "        i, j = map(int, key.split('_'))\n",
        "        pdf.multi_cell(0, 8,\n",
        "            f\"Comparación {model_names[i]} vs {model_names[j]}:\\n\"\n",
        "            f\"Estadístico de McNemar = {stat:.4f}, p-value = {p:.4f}\\n\"\n",
        "        )\n",
        "\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.cell(0, 10, \"Matrices de Confusión\", ln=1)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    x_positions = [10, 110]\n",
        "    y = pdf.get_y()\n",
        "    for idx, img_path in enumerate(confusion_images):\n",
        "        col = idx % 2\n",
        "        if idx and col == 0:\n",
        "            y += 80\n",
        "        pdf.set_xy(x_positions[col], y)\n",
        "        pdf.cell(90, 10, txt=f\"Matriz de Confusión - {model_names[idx]}\", ln=2)\n",
        "        pdf.set_x(x_positions[col])\n",
        "        pdf.image(img_path, x=x_positions[col], y=pdf.get_y(), w=80)\n",
        "\n",
        "    pdf.output(output_path)\n",
        "    return output_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMrlG-81BNqv",
        "outputId": "0f51b056-21f3-4312-cd06-04a622fa92e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting report_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 8 – Curvas ROC, métricas y matrices de confusión"
      ],
      "metadata": {
        "id": "4chjHxShBPBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Celda 8: Evaluación eficiente por modelo ===\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    confusion_matrix\n",
        ")\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Parámetros\n",
        "TEST_DIR   = '/content/filtered_data'\n",
        "IMG_SIZE   = 512\n",
        "BATCH_SIZE = 4\n",
        "MODEL_PATHS = {\n",
        "    'ResNet50':    '/content/models/ResNet50.h5',\n",
        "    'InceptionV3': '/content/models/InceptionV3.h5',\n",
        "    'DenseNet121': '/content/models/DenseNet121.h5',\n",
        "    'CustomCNN':   '/content/models/CustomCNN.h5'\n",
        "}\n",
        "\n",
        "# Función helper para predecir por batch desde disco sin cargar todo en memoria\n",
        "def evaluate_with_generator(model, test_dir, img_size=512, batch_size=4, color_mode='rgb'):\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    gen = ImageDataGenerator(rescale=1./255)\n",
        "    flow = gen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        classes=['benign','malignant'],\n",
        "        class_mode='binary',\n",
        "        color_mode=color_mode,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "    probas = model.predict(flow, verbose=1)\n",
        "    preds  = (probas.ravel() > 0.5).astype(int)\n",
        "    return flow.classes, probas.ravel(), preds\n",
        "\n",
        "# Diccionarios para guardar resultados\n",
        "probas_dict = {}\n",
        "preds_dict  = {}\n",
        "cm_dict     = {}\n",
        "roc_dict    = {}\n",
        "y_true      = None\n",
        "\n",
        "# 1) Evaluar cada modelo por separado\n",
        "for name, path in MODEL_PATHS.items():\n",
        "    print(f\"\\n▶️ Evaluando {name}\")\n",
        "    model = load_model(path)\n",
        "    mode = 'grayscale' if name=='CustomCNN' else 'rgb'\n",
        "    y_true, probas, preds = evaluate_with_generator(model, TEST_DIR,\n",
        "                                                    img_size=IMG_SIZE,\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    color_mode=mode)\n",
        "    probas_dict[name] = probas\n",
        "    preds_dict[name]  = preds\n",
        "    cm = confusion_matrix(y_true, preds)\n",
        "    cm_dict[name]     = cm\n",
        "    fpr, tpr, _       = roc_curve(y_true, probas)\n",
        "    roc_dict[name]    = (fpr, tpr)\n",
        "    # liberar memoria\n",
        "    del model\n",
        "    K.clear_session()\n",
        "\n",
        "# 2) Curvas ROC comparativas\n",
        "plt.figure(figsize=(8,6))\n",
        "for name, (fpr, tpr) in roc_dict.items():\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc(fpr,tpr):.2f})\")\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.title(\"Curvas ROC comparativas\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 3) Classification report, MCC y matrices de confusión\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "for name in MODEL_PATHS:\n",
        "    print(f\"\\n--- Reporte para {name} ---\")\n",
        "    y_pred = preds_dict[name]\n",
        "    print(classification_report(y_true, y_pred, target_names=['benign','malignant']))\n",
        "    print(f\"MCC: {matthews_corrcoef(y_true, y_pred):.3f}\")\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm_dict[name], annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['benign','malignant'],\n",
        "                yticklabels=['benign','malignant'])\n",
        "    plt.title(f\"Matriz de Confusión — {name}\")\n",
        "    plt.xlabel(\"Predicción\")\n",
        "    plt.ylabel(\"Verdadero\")\n",
        "    plt.show()\n",
        "\n",
        "# 4) Pruebas de McNemar entre todos los pares\n",
        "from metrics_utils import mcnemar_test\n",
        "print(\"\\n=== Pruebas de McNemar ===\")\n",
        "model_names = list(MODEL_PATHS.keys())\n",
        "for i in range(len(model_names)):\n",
        "    for j in range(i+1, len(model_names)):\n",
        "        stat, p = mcnemar_test(\n",
        "            y_true,\n",
        "            preds_dict[model_names[i]],\n",
        "            preds_dict[model_names[j]]\n",
        "        )\n",
        "        print(f\"{model_names[i]} vs {model_names[j]}: estadístico={stat:.4f}, p-value={p:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "be1PI9GTBQB6",
        "outputId": "2ce6656c-cde2-4e97-ae8b-a0add6c826b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶️ Evaluando ResNet50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1312 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 23/328\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:21\u001b[0m 4s/step"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-1399406528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grayscale'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'CustomCNN'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     y_true, probas, preds = evaluate_with_generator(model, TEST_DIR,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                                     \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-23-1399406528.py\u001b[0m in \u001b[0;36mevaluate_with_generator\u001b[0;34m(model, test_dir, img_size, batch_size, color_mode)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mpreds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Celda 9 – Comparación estadística e informe PDF"
      ],
      "metadata": {
        "id": "xRjmBguwBSGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Celda 9: Evaluación con generadores por canal ===\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from metrics_utils import matthews_corrcoef, mcnemar_test\n",
        "from report_utils  import generate_comparison_report\n",
        "\n",
        "# Parámetros\n",
        "TEST_DIR    = '/content/filtered_data'   # carpetas benign/ y malignant/\n",
        "IMG_SIZE    = (512, 512)\n",
        "BATCH_SIZE  = 4\n",
        "MODEL_PATHS = {\n",
        "    'ResNet50'   : '/content/models/ResNet50.h5',\n",
        "    'InceptionV3': '/content/models/InceptionV3.h5',\n",
        "    'DenseNet121': '/content/models/DenseNet121.h5',\n",
        "    'CustomCNN'  : '/content/models/CustomCNN.h5'\n",
        "}\n",
        "\n",
        "# 1) Definimos dos validadores: uno RGB y uno grayscale\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_gen_rgb = datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "val_gen_gray = datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    classes=['benign','malignant'],\n",
        "    class_mode='binary',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# extraemos y guardamos la etiqueta verdadera\n",
        "y_true = val_gen_rgb.classes\n",
        "\n",
        "metrics_list = []\n",
        "all_preds    = []\n",
        "cm_paths     = []\n",
        "\n",
        "# 2) Iteramos por cada modelo\n",
        "for name, model_path in MODEL_PATHS.items():\n",
        "    print(f\"\\n▶️ Evaluando {name}\")\n",
        "    model = tf.keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "    # 2a) Elegimos generador según el modelo\n",
        "    gen = val_gen_gray if name == 'CustomCNN' else val_gen_rgb\n",
        "\n",
        "    # 2b) Predecimos en lote\n",
        "    y_prob = model.predict(gen, verbose=0).ravel()\n",
        "    y_pred = (y_prob > 0.5).astype(int)\n",
        "    all_preds.append(y_pred)\n",
        "\n",
        "    # 2c) Cálculo de métricas\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=['benign','malignant'],\n",
        "        output_dict=True\n",
        "    )\n",
        "    metrics_list.append({\n",
        "        'model'      : name,\n",
        "        'accuracy'   : report['accuracy'],\n",
        "        'sensitivity': report['malignant']['recall'],\n",
        "        'specificity': report['benign']['recall'],\n",
        "        'f1'         : report['malignant']['f1-score'],\n",
        "        'mcc'        : matthews_corrcoef(cm)\n",
        "    })\n",
        "\n",
        "    # 2d) Guardamos la matriz de confusión como PNG\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['benign','malignant'],\n",
        "                yticklabels=['benign','malignant'])\n",
        "    plt.title(f'Matriz de Confusión – {name}')\n",
        "    plt.xlabel('Predicción')\n",
        "    plt.ylabel('Verdadero')\n",
        "    cm_path = f'cm_{name}.png'\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    cm_paths.append(cm_path)\n",
        "\n",
        "    # 2e) Liberamos el modelo de la sesión\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "# 3) Pruebas de McNemar entre pares\n",
        "comparisons = {}\n",
        "names = list(MODEL_PATHS.keys())\n",
        "for (i,_), (j,_) in combinations(enumerate(names), 2):\n",
        "    stat, pval = mcnemar_test(y_true, all_preds[i], all_preds[j])\n",
        "    comparisons[f'{i}_{j}'] = (stat, pval)\n",
        "\n",
        "# 4) Generar PDF comparativo\n",
        "pdf_path = generate_comparison_report(\n",
        "    metrics_list     = metrics_list,\n",
        "    model_names      = names,\n",
        "    comparisons      = comparisons,\n",
        "    confusion_images = cm_paths,\n",
        "    output_path      = 'comparativo_mama.pdf'\n",
        ")\n",
        "print(f\"\\n✅ Reporte comparativo generado en: {pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "I6Gw6FmIBTF5",
        "outputId": "ec83c169-1ef6-441b-9120-5039f711c6f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1312 images belonging to 2 classes.\n",
            "Found 1312 images belonging to 2 classes.\n",
            "\n",
            "▶️ Evaluando ResNet50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-3732480945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# 2b) Predecimos en lote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### aplicacion en streamlit"
      ],
      "metadata": {
        "id": "5qjkWApnBUqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model_utils import load_models, predict_image, predict_image_rgb, generate_saliency_map\n",
        "from preprocessing import load_and_preprocess_image\n",
        "from report_utils import generate_multi_model_report  # Asegúrate que existe esta función\n",
        "\n",
        "st.set_page_config(page_title=\"Diagnóstico Cáncer de Mama\", layout=\"wide\")\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"CustomCNN\":   \"/content/models/CustomCNN.h5\",\n",
        "    \"DenseNet121\": \"/content/models/DenseNet121.h5\",\n",
        "    \"InceptionV3\": \"/content/models/InceptionV3.h5\",\n",
        "    \"ResNet50\":    \"/content/models/ResNet50.h5\",\n",
        "}\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model_dict(selected_names):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    ret = {}\n",
        "    for name in selected_names:\n",
        "        ret[name] = load_model(MODEL_PATHS[name], compile=False)\n",
        "    return ret\n",
        "\n",
        "st.title(\"🩺 Sistema de Diagnóstico de Cáncer de Mama\")\n",
        "\n",
        "# --- Paso 1: Selección de modelos ---\n",
        "st.sidebar.header(\"Paso 1: Elige modelos\")\n",
        "all_names = list(MODEL_PATHS.keys())\n",
        "sel_models = st.sidebar.multiselect(\n",
        "    \"Modelos a usar para inferencia\",\n",
        "    all_names,\n",
        "    default=[\"DenseNet121\"]\n",
        ")\n",
        "\n",
        "# --- Paso 2: Carga de imagen ---\n",
        "st.sidebar.header(\"Paso 2: Carga imagen\")\n",
        "uploaded = st.sidebar.file_uploader(\"PNG de ultrasonido\", type=\"png\")\n",
        "if not uploaded:\n",
        "    st.info(\"Por favor sube una imagen PNG.\")\n",
        "    st.stop()\n",
        "\n",
        "# --- Preprocesado ---\n",
        "img_preprocessed, img_original = load_and_preprocess_image(uploaded)\n",
        "# Si la imagen no está en [0,1], normalízala aquí:\n",
        "if img_preprocessed.max() > 1.0:\n",
        "    img_preprocessed = img_preprocessed / 255.0\n",
        "\n",
        "st.subheader(\"Imagen Original y Preprocesada\")\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    st.image(img_original, caption=\"Original 512×512\", use_column_width=True)\n",
        "with col2:\n",
        "    st.image(img_preprocessed, caption=\"Preprocesada 512×512\", use_column_width=True)\n",
        "\n",
        "models = load_model_dict(sel_models)\n",
        "\n",
        "# --- Inferencia correcta según modelo ---\n",
        "results = []\n",
        "for name, mdl in models.items():\n",
        "    if name == \"CustomCNN\":\n",
        "        x = img_preprocessed\n",
        "        if x.ndim == 2:              # (512,512) → (512,512,1)\n",
        "            x = x[..., None]\n",
        "    else:\n",
        "        x = img_preprocessed\n",
        "        if x.ndim == 2:              # (512,512) → (512,512,3)\n",
        "            x = np.stack([x]*3, axis=-1)\n",
        "        elif x.shape[-1] == 1:       # (512,512,1) → (512,512,3)\n",
        "            x = np.repeat(x, 3, axis=-1)\n",
        "        # ahora x.shape == (512,512,3)\n",
        "    y_prob = float(mdl.predict(x[np.newaxis, ...])[0,0])\n",
        "    y_pred = int(y_prob > 0.5)\n",
        "    confidence = (y_prob if y_pred else 1 - y_prob) * 100\n",
        "    saliency = generate_saliency_map(mdl, x)\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"prediction\": y_pred,\n",
        "        \"probability\": y_prob,\n",
        "        \"confidence\": confidence,\n",
        "        \"saliency\": saliency\n",
        "    })\n",
        "\n",
        "# --- Mostrar resultados ---\n",
        "st.subheader(\"Resultados por modelo\")\n",
        "for res in results:\n",
        "    st.markdown(f\"### {res['model']}\")\n",
        "    c1, c2, c3 = st.columns([1,1,1])\n",
        "    with c1:\n",
        "        st.metric(\"Diagnóstico\", \"Maligno\" if res[\"prediction\"] else \"Benigno\")\n",
        "    with c2:\n",
        "        st.metric(\"Confianza\", f\"{res['confidence']:.2f}%\")\n",
        "    with c3:\n",
        "        st.metric(\"Probabilidad de malignidad\", f\"{res['probability']:.2%}\")\n",
        "    fig, ax = plt.subplots(figsize=(4,4))\n",
        "    ax.imshow(img_original, cmap='gray')\n",
        "    ax.imshow(res[\"saliency\"], cmap='jet', alpha=0.5)\n",
        "    ax.axis('off')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# --- Descargar reporte PDF multi-modelo ---\n",
        "if st.button(\"📄 Descargar reporte PDF consolidado\"):\n",
        "    pdf_path = generate_multi_model_report(\n",
        "        image_original=img_original,\n",
        "        results=results,\n",
        "        output_path=\"diagnostico_mama_multimodelo.pdf\"\n",
        "    )\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        st.download_button(\n",
        "            label=\"📥 Descargar PDF\",\n",
        "            data=f,\n",
        "            file_name=\"diagnostico_mama_multimodelo.pdf\",\n",
        "            mime=\"application/pdf\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7zrB0_yBVeJ",
        "outputId": "2fec3ec3-12ea-4270-e415-d89e7335fc3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = \"2zrmyWJvn4NqAIU37xGlUdrzN9i_6mXN47us3RSGewJN1k8js\"\n",
        "\n",
        "# abre el túnel HTTP al puerto 8501 (Streamlit)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🌐 App disponible en:\", public_url)\n",
        "!streamlit run app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsBGDXvlBWxw",
        "outputId": "dec683f2-a588-41d7-9f98-86c8692822e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "🌐 App disponible en: NgrokTunnel: \"https://907c78738b49.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.173.241:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-07-14 20:37:45.376919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752525465.522478   28848 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752525465.566130   28848 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-14 20:37:45.685792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-07-14 20:37:54.577 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-07-14 20:37:54.582 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-07-14 20:37:55.170276: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "2025-07-14 21:01:48.835 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-07-14 21:01:48.840 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "2025-07-14 21:02:00.146 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-07-14 21:02:00.151 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        }
      ]
    }
  ]
}